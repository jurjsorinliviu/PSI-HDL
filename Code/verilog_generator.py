"""
Verilog-A Generator for Psi-HDL Framework
Translates extracted neural network structures to Verilog-A hardware description language.

Author: Psi-HDL Pipeline
"""

import numpy as np
from typing import Dict, List, Tuple, Any
from structure_extractor import NetworkStructure
import os


class VerilogAGenerator:
    """Generate Verilog-A code from extracted network structure"""
    
    def __init__(self, structure: NetworkStructure):
        """
        Initialize Verilog-A generator
        
        Args:
            structure: NetworkStructure object from structure_extractor
        """
        self.structure = structure
        self.module_name = f"psi_nn_{structure.metadata['model_type']}"
        self.voltage_scale = 1.0  # Voltage scaling factor (e.g., 1V = 1.0 in normalized space)
        self.current_scale = 1e-3  # Current scaling (1mA nominal)
        
    def generate(self, output_path: str = None) -> str:
        """
        Generate complete Verilog-A module
        
        Args:
            output_path: Optional path to save generated code
            
        Returns:
            Generated Verilog-A code as string
        """
        print(f"Generating Verilog-A code for {self.structure.metadata['model_type']}...")
        
        # Build complete module
        code_parts = []
        code_parts.append(self._generate_header())
        code_parts.append(self._generate_module_declaration())
        code_parts.append(self._generate_parameters())
        code_parts.append(self._generate_variables())
        code_parts.append(self._generate_analog_block())
        code_parts.append(self._generate_footer())
        
        verilog_code = "\n".join(code_parts)
        
        # Save to file if path provided
        if output_path:
            with open(output_path, 'w') as f:
                f.write(verilog_code)
            print(f"Verilog-A code saved to {output_path}")
        
        return verilog_code
    
    def _generate_header(self) -> str:
        """Generate file header with comments"""
        header = f"""// Verilog-A Neural Network Module
// Auto-generated by Psi-HDL Framework
// Model Type: {self.structure.metadata['model_type']}
// Input Dimension: {self.structure.input_dim}
// Output Dimension: {self.structure.output_dim}
// Total Layers: {self.structure.metadata['total_layers']}
//
// This module implements a neural network discovered by Psi-NN
// as an analog behavioral model suitable for SPICE simulation.

`include "constants.vams"
`include "disciplines.vams"
"""
        return header
    
    def _generate_module_declaration(self) -> str:
        """Generate module declaration with ports"""
        # Input ports (voltages for each input dimension)
        input_ports = ", ".join([f"in{i}" for i in range(self.structure.input_dim)])
        
        # Output ports (voltages for each output dimension)
        output_ports = ", ".join([f"out{i}" for i in range(self.structure.output_dim)])
        
        # Add power supplies
        all_ports = f"{input_ports}, {output_ports}, vdd, vss"
        
        declaration = f"""
module {self.module_name}({all_ports});
    // Input ports (voltage nodes)
"""
        
        for i in range(self.structure.input_dim):
            declaration += f"    input in{i};\n"
            
        declaration += "\n    // Output ports (voltage nodes)\n"
        for i in range(self.structure.output_dim):
            declaration += f"    output out{i};\n"
            
        declaration += """
    // Power supply nodes
    input vdd, vss;
    
    // Declare port types as electrical
"""
        
        for i in range(self.structure.input_dim):
            declaration += f"    electrical in{i};\n"
        for i in range(self.structure.output_dim):
            declaration += f"    electrical out{i};\n"
        declaration += "    electrical vdd, vss;\n"
        
        return declaration
    
    def _generate_parameters(self) -> str:
        """Generate parameter declarations for weights and biases"""
        params = """
    // Neural network parameters (weights and biases)
    // These can be overridden during instantiation
"""
        
        model_type = self.structure.metadata['model_type']
        
        if "PsiNN" in model_type:
            # For PsiNN models, generate parameters for discovered structures
            params += self._generate_psinn_parameters()
        else:
            # For standard PINN models
            params += self._generate_pinn_parameters()
        
        return params
    
    def _generate_psinn_parameters(self) -> str:
        """Generate parameters for PsiNN special structures"""
        params = ""
        layer_idx = 0
        
        for layer in self.structure.layers:
            if layer['type'] == 'psi_plus_minus':
                # Extract dimensions from first layer component
                first_key = list([k for k in layer.keys() if k.startswith('fc')])[0]
                w_shape = layer[first_key]['weight_shape']
                
                params += f"\n    // Layer {layer_idx}: {layer['name']} ({layer['type']})\n"
                for key in layer.keys():
                    if key.startswith('fc'):
                        shape = layer[key]['weight_shape']
                        params += f"    parameter real {key}_w[0:{shape[0]-1}][0:{shape[1]-1}] = 0.0;\n"
                        if layer[key].get('has_bias', False):
                            params += f"    parameter real {key}_b[0:{shape[0]-1}] = 0.0;\n"
                            
            elif layer['type'] in ['psi_symmetric', 'psi_combination']:
                params += f"\n    // Layer {layer_idx}: {layer['name']} ({layer['type']})\n"
                for key in layer.keys():
                    if key.startswith('fc'):
                        shape = layer[key]['weight_shape']
                        params += f"    parameter real {key}_w[0:{shape[0]-1}][0:{shape[1]-1}] = 0.0;\n"
                        if layer[key].get('has_bias', False):
                            params += f"    parameter real {key}_b[0:{shape[0]-1}] = 0.0;\n"
                            
            elif layer['type'] == 'linear':
                params += f"\n    // Layer {layer_idx}: {layer['name']} (output)\n"
                shape = layer['weight_shape']
                params += f"    parameter real {layer['name']}_w[0:{shape[0]-1}][0:{shape[1]-1}] = 0.0;\n"
                if layer.get('has_bias', False):
                    params += f"    parameter real {layer['name']}_b[0:{shape[0]-1}] = 0.0;\n"
            
            layer_idx += 1
        
        return params
    
    def _generate_pinn_parameters(self) -> str:
        """Generate parameters for standard PINN layers"""
        params = ""
        
        for layer in self.structure.layers:
            if layer['type'] == 'linear':
                shape = layer['weight_shape']
                layer_name = layer['name'].replace('layer_', 'L')
                
                params += f"\n    // {layer['name']}\n"
                params += f"    parameter real {layer_name}_w[0:{shape[0]-1}][0:{shape[1]-1}] = 0.0;\n"
                
                if layer['has_bias']:
                    params += f"    parameter real {layer_name}_b[0:{shape[0]-1}] = 0.0;\n"
        
        return params
    
    def _generate_variables(self) -> str:
        """Generate internal variable declarations"""
        variables = """
    // Internal variables for layer computations
    real input_vec[0:{}];
    real output_vec[0:{}];
""".format(self.structure.input_dim - 1, self.structure.output_dim - 1)
        
        # Add intermediate layer variables
        max_nodes = 0
        for layer in self.structure.layers:
            if 'output_dim' in layer and layer['output_dim'] > max_nodes:
                max_nodes = layer['output_dim']
        
        variables += f"    real layer_out[0:{max_nodes-1}];\n"
        variables += "    real temp_sum;\n"
        variables += "    integer i, j;\n"
        
        return variables
    
    def _generate_analog_block(self) -> str:
        """Generate main analog computation block"""
        analog = """
    analog begin
        // Read input voltages and normalize
"""
        
        # Read inputs
        for i in range(self.structure.input_dim):
            analog += f"        input_vec[{i}] = V(in{i}) / {self.voltage_scale};\n"
        
        analog += "\n        // Forward propagation through network\n"
        
        model_type = self.structure.metadata['model_type']
        
        if "PsiNN_burgers" in model_type:
            analog += self._generate_burgers_forward()
        elif "PsiNN_laplace" in model_type:
            analog += self._generate_laplace_forward()
        else:
            analog += self._generate_pinn_forward()
        
        # Write outputs
        analog += "\n        // Write output voltages\n"
        for i in range(self.structure.output_dim):
            analog += f"        V(out{i}) <+ output_vec[{i}] * {self.voltage_scale};\n"
        
        analog += "    end\n"
        
        return analog
    
    def _generate_burgers_forward(self) -> str:
        """Generate forward pass for Burgers PsiNN structure"""
        forward = """
        // Layer 1: +/- structure with tanh activation
        // u1_1 = tanh(fc1_1(x) + fc1_3(y))
        // u1_2 = tanh(fc1_1(x) - fc1_3(y))
        
        // Compute fc1_1(x) contribution
        temp_sum = 0.0;
        for (i = 0; i < 1; i = i + 1) begin
            temp_sum = fc1_1_w[0][i] * input_vec[0] + fc1_1_b[0];
        end
        
        // Branch 1: + fc1_3(y)
        layer_out[0] = tanh(temp_sum + fc1_3_w[0][0] * input_vec[1]);
        
        // Branch 2: - fc1_3(y)
        layer_out[1] = tanh(temp_sum - fc1_3_w[0][0] * input_vec[1]);
        
        // Layer 2: Symmetric weight sharing
        // u2_1 = tanh(fc2_1(u1_1) + fc2_3(u1_2))
        // u2_2 = tanh(fc2_3(u1_1) + fc2_1(u1_2))
        // u2_3 = tanh(fc2_2(u1_1) - fc2_2(u1_2))
        
        // Store previous layer output
        real u1_1, u1_2;
        u1_1 = layer_out[0];
        u1_2 = layer_out[1];
        
        // Branch 1: fc2_1(u1_1) + fc2_3(u1_2)
        layer_out[0] = tanh(fc2_1_w[0][0] * u1_1 + fc2_1_b[0] + 
                           fc2_3_w[0][0] * u1_2 + fc2_3_b[0]);
        
        // Branch 2: fc2_3(u1_1) + fc2_1(u1_2)
        layer_out[1] = tanh(fc2_3_w[0][0] * u1_1 + fc2_3_b[0] + 
                           fc2_1_w[0][0] * u1_2 + fc2_1_b[0]);
        
        // Branch 3: fc2_2(u1_1) - fc2_2(u1_2)
        layer_out[2] = tanh(fc2_2_w[0][0] * (u1_1 - u1_2));
        
        // Layer 3: Combination
        // u3_1 = tanh(fc3_1(u2_1) - fc3_1(u2_2) + fc3_2(u2_3))
        real u2_1, u2_2, u2_3;
        u2_1 = layer_out[0];
        u2_2 = layer_out[1];
        u2_3 = layer_out[2];
        
        layer_out[0] = tanh(fc3_1_w[0][0] * u2_1 + fc3_1_b[0] - 
                           (fc3_1_w[0][0] * u2_2 + fc3_1_b[0]) +
                           fc3_2_w[0][0] * u2_3);
        
        // Layer 4: Output (linear, no bias for odd function)
        output_vec[0] = output_w[0][0] * layer_out[0];
"""
        return forward
    
    def _generate_laplace_forward(self) -> str:
        """Generate forward pass for Laplace PsiNN structure"""
        forward = """
        // Layer 1: +/- structure with tanh activation
        // u1_3 = tanh(fc1_2(x) + fc1_4(y))
        // u1_4 = tanh(fc1_2(x) - fc1_4(y))
        
        temp_sum = fc1_2_w[0][0] * input_vec[0] + fc1_2_b[0];
        
        layer_out[0] = tanh(temp_sum + fc1_4_w[0][0] * input_vec[1]);
        layer_out[1] = tanh(temp_sum - fc1_4_w[0][0] * input_vec[1]);
        
        // Layer 2: Symmetric interchange
        // u2_3 = tanh(fc2_2(u1_3) + fc2_4(u1_4))
        // u2_4 = tanh(fc2_4(u1_3) + fc2_2(u1_4))
        
        real u1_3, u1_4;
        u1_3 = layer_out[0];
        u1_4 = layer_out[1];
        
        layer_out[0] = tanh(fc2_2_w[0][0] * u1_3 + fc2_2_b[0] + 
                           fc2_4_w[0][0] * u1_4 + fc2_4_b[0]);
        layer_out[1] = tanh(fc2_4_w[0][0] * u1_3 + fc2_4_b[0] + 
                           fc2_2_w[0][0] * u1_4 + fc2_2_b[0]);
        
        // Layer 3: Addition
        // u3_2 = tanh(fc3_2(u2_3) + fc3_2(u2_4))
        real u2_3, u2_4;
        u2_3 = layer_out[0];
        u2_4 = layer_out[1];
        
        layer_out[0] = tanh(fc3_2_w[0][0] * (u2_3 + u2_4) + fc3_2_b[0]);
        
        // Layer 4: Output (linear with bias for even function)
        output_vec[0] = output_w[0][0] * layer_out[0] + output_b[0];
"""
        return forward
    
    def _generate_pinn_forward(self) -> str:
        """Generate forward pass for standard PINN"""
        forward = "        // Standard feedforward network\n"
        forward += "        real layer_in[0:100];\n"
        forward += "        real layer_temp[0:100];\n\n"
        
        forward += "        // Copy inputs\n"
        forward += "        for (i = 0; i < {}; i = i + 1) begin\n".format(self.structure.input_dim)
        forward += "            layer_in[i] = input_vec[i];\n"
        forward += "        end\n\n"
        
        linear_layers = [l for l in self.structure.layers if l['type'] == 'linear']
        
        for idx, layer in enumerate(linear_layers):
            layer_name = layer['name'].replace('layer_', 'L')
            in_dim = layer['input_dim']
            out_dim = layer['output_dim']
            
            forward += f"        // Layer {idx}: {in_dim} -> {out_dim}\n"
            forward += f"        for (i = 0; i < {out_dim}; i = i + 1) begin\n"
            forward += "            temp_sum = 0.0;\n"
            forward += f"            for (j = 0; j < {in_dim}; j = j + 1) begin\n"
            forward += f"                temp_sum = temp_sum + {layer_name}_w[i][j] * layer_in[j];\n"
            forward += "            end\n"
            
            if layer['has_bias']:
                forward += f"            temp_sum = temp_sum + {layer_name}_b[i];\n"
            
            # Apply activation if not last layer
            if idx < len(linear_layers) - 1:
                forward += "            layer_temp[i] = tanh(temp_sum);\n"
            else:
                forward += "            layer_temp[i] = temp_sum;\n"
            
            forward += "        end\n\n"
            
            # Copy to next layer input
            forward += f"        for (i = 0; i < {out_dim}; i = i + 1) begin\n"
            forward += "            layer_in[i] = layer_temp[i];\n"
            forward += "        end\n\n"
        
        forward += "        // Copy to output\n"
        forward += "        for (i = 0; i < {}; i = i + 1) begin\n".format(self.structure.output_dim)
        forward += "            output_vec[i] = layer_in[i];\n"
        forward += "        end\n"
        
        return forward
    
    def _generate_footer(self) -> str:
        """Generate module footer"""
        return "\nendmodule\n"
    
    def generate_weight_file(self, model, output_path: str):
        """
        Generate a parameter file with actual weight values
        
        Args:
            model: PyTorch model with trained weights
            output_path: Path to save parameter file
        """
        print(f"Generating weight parameter file...")
        
        params = []
        params.append("// Weight parameters for Verilog-A module")
        params.append(f"// Model: {self.structure.metadata['model_type']}\n")
        
        # Extract weights from model
        for name, param in model.named_parameters():
            weight = param.detach().cpu().numpy()
            
            # Format parameter name for Verilog-A
            param_name = name.replace('.', '_')
            
            if len(weight.shape) == 2:  # Weight matrix
                params.append(f"// {param_name}: shape {weight.shape}")
                for i in range(weight.shape[0]):
                    for j in range(weight.shape[1]):
                        params.append(f".{param_name}[{i}][{j}]({weight[i,j]:.6e})")
            elif len(weight.shape) == 1:  # Bias vector
                params.append(f"// {param_name}: shape {weight.shape}")
                for i in range(weight.shape[0]):
                    params.append(f".{param_name}[{i}]({weight[i]:.6e})")
        
        param_text = "\n".join(params)
        
        with open(output_path, 'w') as f:
            f.write(param_text)
        
        print(f"Weight parameters saved to {output_path}")
        return param_text
    
    def generate_testbench(self, test_points: np.ndarray, output_path: str):
        """
        Generate SPICE testbench for simulation
        
        Args:
            test_points: NumPy array of test input points [N x input_dim]
            output_path: Path to save testbench file
        """
        print(f"Generating SPICE testbench...")
        
        tb = []
        tb.append("* SPICE Testbench for Psi-NN Verilog-A Module")
        tb.append(f"* Model: {self.structure.metadata['model_type']}")
        tb.append("* Auto-generated by Psi-HDL Framework\n")
        
        tb.append(".title Psi-NN Neural Network Test\n")
        
        # Include Verilog-A module
        verilog_file = output_path.replace('.sp', '.va')
        tb.append(f".hdl {verilog_file}\n")
        
        tb.append("* Power supplies")
        tb.append("Vdd vdd 0 DC 5.0")
        tb.append("Vss vss 0 DC 0.0\n")
        
        tb.append("* Input voltage sources (DC sweep will be used)")
        for i in range(self.structure.input_dim):
            tb.append(f"Vin{i} in{i} 0 DC 0.0")
        
        tb.append("\n* Device under test")
        tb.append(f"XDUT in0 in1 out0 vdd vss {self.module_name}\n")
        
        tb.append("* Load resistors")
        for i in range(self.structure.output_dim):
            tb.append(f"Rload{i} out{i} 0 1MEG")
        
        tb.append("\n* Analysis")
        tb.append("* DC sweep to test network response")
        
        # Generate sweep parameters based on test points
        x_min, x_max = test_points[:, 0].min(), test_points[:, 0].max()
        y_min, y_max = test_points[:, 1].min(), test_points[:, 1].max()
        
        tb.append(f".dc Vin0 {x_min} {x_max} 0.1 Vin1 {y_min} {y_max} 0.1")
        tb.append(".print dc v(in0) v(in1) v(out0)")
        tb.append(".control")
        tb.append("run")
        tb.append("plot v(out0)")
        tb.append(".endc")
        tb.append("\n.end")
        
        tb_text = "\n".join(tb)
        
        with open(output_path, 'w') as f:
            f.write(tb_text)
        
        print(f"SPICE testbench saved to {output_path}")
        return tb_text


def generate_complete_hdl_package(structure: NetworkStructure, model, output_dir: str, 
                                  test_points: np.ndarray = None):
    """
    Generate complete HDL package with Verilog-A, parameters, and testbench
    
    Args:
        structure: NetworkStructure from extraction
        model: PyTorch model with trained weights
        output_dir: Directory to save all generated files
        test_points: Optional test points for validation
    """
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    generator = VerilogAGenerator(structure)
    
    # Generate main Verilog-A module
    va_path = os.path.join(output_dir, f"{generator.module_name}.va")
    generator.generate(va_path)
    
    # Generate weight parameters
    param_path = os.path.join(output_dir, f"{generator.module_name}_params.txt")
    generator.generate_weight_file(model, param_path)
    
    # Generate testbench if test points provided
    if test_points is not None:
        tb_path = os.path.join(output_dir, f"{generator.module_name}_tb.sp")
        generator.generate_testbench(test_points, tb_path)
    
    print(f"\nComplete HDL package generated in: {output_dir}")
    print(f"  - Verilog-A module: {va_path}")
    print(f"  - Parameters: {param_path}")
    if test_points is not None:
        print(f"  - Testbench: {tb_path}")